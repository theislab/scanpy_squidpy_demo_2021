{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba==0.52 in /Users/giovanni.palla/miniconda3/envs/spatial/lib/python3.8/site-packages (0.52.0)\n",
      "Requirement already satisfied: setuptools in /Users/giovanni.palla/miniconda3/envs/spatial/lib/python3.8/site-packages (from numba==0.52) (49.6.0.post20210108)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/giovanni.palla/miniconda3/envs/spatial/lib/python3.8/site-packages (from numba==0.52) (1.20.1)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /Users/giovanni.palla/miniconda3/envs/spatial/lib/python3.8/site-packages (from numba==0.52) (0.35.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install squidpy\n",
    "!pip install numba==0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze Visium H&E data\n",
    "=======================\n",
    "\n",
    "This tutorial shows how to apply Squidpy for the analysis of Visium\n",
    "spatial transcriptomics data.\n",
    "\n",
    "The dataset used here consists of a Visium slide of a coronal section of\n",
    "the mouse brain. The original dataset is publicly available at the 10x\n",
    "genomics [dataset\n",
    "portal](https://support.10xgenomics.com/spatial-gene-expression/datasets)\n",
    ". Here, we provide a pre-processed dataset, with pre-annotated clusters,\n",
    "in AnnData format and the tissue image in `squidpy.im.ImageContainer`\n",
    "format.\n",
    "\n",
    "A couple of notes on pre-processing:\n",
    "\n",
    "-   The pre-processing pipeline is the same as the one shown in the\n",
    "    original [Scanpy\n",
    "    tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html)\n",
    "    .\n",
    "-   The cluster annotation was performed using several resources, such\n",
    "    as the [Allen Brain\n",
    "    Atlas](http://mouse.brain-map.org/experiment/thumbnails/100048576?image_type=atlas)\n",
    "    , the [Mouse Brain gene expression\n",
    "    atlas](http://mousebrain.org/genesearch.html) from the Linnarson lab\n",
    "    and this recent\n",
    "    [pre-print](https://www.biorxiv.org/content/10.1101/2020.07.24.219758v1)\n",
    "    .\n",
    "\n",
    "::: {.seealso}\n",
    "See `sphx_glr_auto_tutorials_tutorial_visium_fluo.py` for a detailed\n",
    "analysis example of image features.\n",
    ":::\n",
    "\n",
    "Import packages & data\n",
    "----------------------\n",
    "\n",
    "To run the notebook locally, create a conda environment as *conda env\n",
    "create -f environment.yml* using this\n",
    "[environment.yml](https://github.com/theislab/squidpy_notebooks/blob/master/environment.yml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import squidpy as sq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sc.logging.print_header()\n",
    "print(f\"squidpy=={sq.__version__}\")\n",
    "\n",
    "# load the pre-processed dataset\n",
    "img = sq.datasets.visium_hne_image()\n",
    "adata = sq.datasets.visium_hne_adata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let\\'s visualize cluster annotation in spatial context with\n",
    "`scanpy.pl.spatial`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image features\n",
    "==============\n",
    "\n",
    "Visium datasets contain high-resolution images of the tissue that was\n",
    "used for the gene extraction. Using the function\n",
    "`squidpy.im.calculate_image_features` you can calculate image features\n",
    "for each Visium spot and create a `obs x features` matrix in `adata`\n",
    "that can then be analyzed together with the `obs x gene` gene expression\n",
    "matrix.\n",
    "\n",
    "By extracting image features we are aiming to get both similar and\n",
    "complementary information to the gene expression values. Similar\n",
    "information is for example present in the case of a tissue with two\n",
    "different cell types whose morphology is different. Such cell type\n",
    "information is then contained in both the gene expression values and the\n",
    "tissue image features.\n",
    "\n",
    "Squidpy contains several feature extractors and a flexible pipeline of\n",
    "calculating features of different scales and sizes. There are several\n",
    "detailed examples of how to use `squidpy.im.calculate_image_features`.\n",
    "`sphx_glr_auto_examples_image_compute_features.py` provides a good\n",
    "starting point for learning more.\n",
    "\n",
    "Here, we will extract [summary]{.title-ref} features at different crop\n",
    "sizes and scales to allow the calculation of multi-scale features and\n",
    "[segmentation]{.title-ref} features. For more information on the summary\n",
    "features, also refer to\n",
    "`sphx_glr_auto_examples_image_compute_summary_features.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate features for different scales (higher value means more context)\n",
    "for scale in [1.0, 2.0]:\n",
    "    feature_name = f\"features_summary_scale{scale}\"\n",
    "    sq.im.calculate_image_features(\n",
    "        adata,\n",
    "        img,\n",
    "        features=\"summary\",\n",
    "        key_added=feature_name,\n",
    "        n_jobs=1,\n",
    "        scale=scale,\n",
    "    )\n",
    "\n",
    "\n",
    "# combine features in one dataframe\n",
    "adata.obsm[\"features\"] = pd.concat(\n",
    "    [adata.obsm[f] for f in adata.obsm.keys() if \"features_summary\" in f], axis=\"columns\"\n",
    ")\n",
    "# make sure that we have no duplicated feature names in the combined table\n",
    "adata.obsm[\"features\"].columns = ad.utils.make_index_unique(adata.obsm[\"features\"].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the extracted image features to compute a new cluster\n",
    "annotation. This could be useful to gain insights in similarities across\n",
    "spots based on image morphology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function returning a clustering\n",
    "def cluster_features(features: pd.DataFrame, like=None):\n",
    "    \"\"\"Calculate leiden clustering of features.\n",
    "\n",
    "    Specify filter of features using `like`.\n",
    "    \"\"\"\n",
    "    # filter features\n",
    "    if like is not None:\n",
    "        features = features.filter(like=like)\n",
    "    # create temporary adata to calculate the clustering\n",
    "    adata = ad.AnnData(features)\n",
    "    # important - feature values are not scaled, so need to scale them before PCA\n",
    "    sc.pp.scale(adata)\n",
    "    # calculate leiden clustering\n",
    "    sc.pp.pca(adata, n_comps=min(10, features.shape[1] - 1))\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.leiden(adata)\n",
    "\n",
    "    return adata.obs[\"leiden\"]\n",
    "\n",
    "\n",
    "# calculate feature clusters\n",
    "adata.obs[\"features_cluster\"] = cluster_features(adata.obsm[\"features\"], like=\"summary\")\n",
    "\n",
    "# compare feature and gene clusters\n",
    "sc.set_figure_params(facecolor=\"white\", figsize=(8, 8))\n",
    "sc.pl.spatial(adata, color=[\"features_cluster\", \"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing gene and feature clusters, we notice that in some regions,\n",
    "they look very similar, like the cluster *Fiber\\_tract*, or clusters\n",
    "around the Hippocampus seems to be roughly recapitulated by the clusters\n",
    "in image feature space. In others, the feature clusters look different,\n",
    "like in the cortex, where the gene clusters show the layered structure\n",
    "of the cortex, and the features clusters rather seem to show different\n",
    "regions of the cortex.\n",
    "\n",
    "This is only a simple, comparative analysis of the image features, note\n",
    "that you could also use the image features to e.g. compute a common\n",
    "image and gene clustering by computing a shared neighbors graph (for\n",
    "instance on concatenated PCAs on both feature spaces).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial statistics and graph analysis\n",
    "=====================================\n",
    "\n",
    "Similar to other spatial data, we can investigate spatial organization\n",
    "by leveraging spatial and graph statistics in Visium data.\n",
    "\n",
    "Neighborhood enrichment\n",
    "-----------------------\n",
    "\n",
    "Computing a neighborhood enrichment can help us identify spots clusters\n",
    "that share a common neighborhood structure across the tissue. We can\n",
    "compute such score with the following function:\n",
    "`squidpy.gr.nhood_enrichment`. In short, it\\'s an enrichment score on\n",
    "spatial proximity of clusters: if spots belonging to two different\n",
    "clusters are often close to each other, then they will have a high score\n",
    "and can be defined as being *enriched*. On the other hand, if they are\n",
    "far apart, and therefore are seldom a neighborhood, the score will be\n",
    "low and they can be defined as *depleted*. This score is based on a\n",
    "permutation-based test, and you can set the number of permutations with\n",
    "the `n_perms` argument (default is 1000).\n",
    "\n",
    "Since the function works on a connectivity matrix, we need to compute\n",
    "that as well. This can be done with `squidpy.gr.spatial_neighbors`.\n",
    "Please see `sphx_glr_auto_examples_graph_compute_spatial_neighbors.py`\n",
    "for more details of how this function works.\n",
    "\n",
    "Finally, we\\'ll directly visualize the results with\n",
    "`squidpy.pl.nhood_enrichment`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.spatial_neighbors(adata)\n",
    "sq.gr.nhood_enrichment(adata, cluster_key=\"cluster\")\n",
    "sq.pl.nhood_enrichment(adata, cluster_key=\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the spatial organization of the mouse brain coronal section, not\n",
    "surprisingly we find high neighborhood enrichment the Hippocampus\n",
    "region: *Pyramidal\\_layer\\_dentate\\_gyrus* and *Pyramidal\\_layer*\n",
    "clusters seems to be often neighbors with the larger *Hippocampus*\n",
    "cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-occurrence across spatial dimensions\n",
    "=======================================\n",
    "\n",
    "In addition to the neighbor enrichment score, we can visualize cluster\n",
    "co-occurrence in spatial dimensions. This is a similar analysis of the\n",
    "one presented above, yet it does not operate on the connectivity matrix,\n",
    "but on the original spatial coordinates. The co-occurrence score is\n",
    "defined as:\n",
    "\n",
    "$$\\frac{p(exp|cond)}{p(exp)}$$\n",
    "\n",
    "where $p(exp|cond)$ is the conditional probability of observing a\n",
    "cluster $exp$ conditioned on the presence of a cluster $cond$, whereas\n",
    "$p(exp)$ is the probability of observing $exp$ in the radius size of\n",
    "interest. The score is computed across increasing radii size around each\n",
    "observation (i.e. spots here) in the tissue.\n",
    "\n",
    "We are gonna compute such score with `squidpy.gr.co_occurrence` and set\n",
    "the cluster annotation for the conditional probability with the argument\n",
    "`clusters`. Then, we visualize the results with\n",
    "`squidpy.pl.co_occurrence`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.co_occurrence(adata, cluster_key=\"cluster\")\n",
    "sq.pl.co_occurrence(\n",
    "    adata,\n",
    "    cluster_key=\"cluster\",\n",
    "    clusters=\"Hippocampus\",\n",
    "    figsize=(8, 4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result largely recapitulates the previous analysis: the\n",
    "*Pyramidal\\_layer* cluster seem to co-occur at short distances with the\n",
    "larger *Hippocampus* cluster. It should be noted that the distance units\n",
    "are given in pixels of the Visium `source_image`, and corresponds to the\n",
    "same unit of the spatial coordinates saved in `adata.obsm[\"spatial\"]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ligand-receptor interaction analysis\n",
    "====================================\n",
    "\n",
    "We are continuing the analysis showing couple of feature-level methods\n",
    "that are very relevant for the analysis of spatial molecular data. For\n",
    "instance, after quantification of cluster co-occurrence, we might be\n",
    "interested in finding molecular instances that could potentially drive\n",
    "cellular communication. This naturally translates in a ligand-receptor\n",
    "interaction analysis. In Squidpy, we provide a fast re-implementation\n",
    "the popular method CellPhoneDB `cellphonedb`\n",
    "([code](https://github.com/Teichlab/cellphonedb) ) and extended its\n",
    "database of annotated ligand-receptor interaction pairs with the popular\n",
    "database *Omnipath* `omnipath`. You can run the analysis for all\n",
    "clusters pairs, and all genes (in seconds, without leaving this\n",
    "notebook), with `squidpy.gr.ligrec`. Furthermore, we\\'ll directly\n",
    "visualize the results, filtering out lowly-expressed genes (with the\n",
    "`means_range` argument) and increasing the threshold for the adjusted\n",
    "p-value (with the `alpha` argument). We\\'ll also subset the\n",
    "visualization for only one source group, the *Hippocampus* cluster, and\n",
    "two target groups, *Pyramidal\\_layer\\_dentate\\_gyrus* and\n",
    "*Pyramidal\\_layer* cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.gr.ligrec(\n",
    "    adata,\n",
    "    n_perms=100,\n",
    "    cluster_key=\"cluster\",\n",
    ")\n",
    "sq.pl.ligrec(\n",
    "    adata,\n",
    "    cluster_key=\"cluster\",\n",
    "    source_groups=\"Hippocampus\",\n",
    "    target_groups=[\"Pyramidal_layer\", \"Pyramidal_layer_dentate_gyrus\"],\n",
    "    means_range=(3, np.inf),\n",
    "    alpha=1e-4,\n",
    "    swap_axes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dotplot visualization provides an interesting set of candidate\n",
    "ligand-receptor annotation that could be involved in cellular\n",
    "interactions in the Hippocampus. A more refined analysis would be for\n",
    "instance to integrate these results with the results of a deconvolution\n",
    "method, to understand what\\'s the proportion of single-cell cell types\n",
    "present in this region of the tissue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatially variable genes with Moran\\'s I\n",
    "========================================\n",
    "\n",
    "Finally, we might be interested in finding genes that show spatial\n",
    "patterns. There are several methods that aimed at address this\n",
    "explicitly, based on point processes or Gaussian process regression\n",
    "framework:\n",
    "\n",
    "-   *SPARK* -\n",
    "    [paper](https://www.nature.com/articles/s41592-019-0701-7#Abs1),\n",
    "    [code](https://github.com/xzhoulab/SPARK).\n",
    "-   *Spatial DE* - [paper](https://www.nature.com/articles/nmeth.4636),\n",
    "    [code](https://github.com/Teichlab/SpatialDE).\n",
    "-   *trendsceek* - [paper](https://www.nature.com/articles/nmeth.4634),\n",
    "    [code](https://github.com/edsgard/trendsceek).\n",
    "-   *HMRF* - [paper](https://www.nature.com/articles/nbt.4260),\n",
    "    [code](https://bitbucket.org/qzhudfci/smfishhmrf-py).\n",
    "\n",
    "Here, we provide a simple approach based on the well-known [Moran\\'s I\n",
    "statistics](https://en.wikipedia.org/wiki/Moran%27s_I) which is in fact\n",
    "used also as a baseline method in the spatially variable gene papers\n",
    "listed above. The function in Squidpy is called `squidpy.gr.moran`, and\n",
    "returns both test statistics and adjusted p-values in\n",
    "`anndata.AnnData.var` slot. For time reasons, we will evaluate a subset\n",
    "of the highly variable genes only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = adata[:, adata.var.highly_variable].var_names.values\n",
    "sq.gr.moran(\n",
    "    adata,\n",
    "    genes=genes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are saved in `adata.uns['moranI']` slot. Genes have already\n",
    "been sorted by Moran\\'s I statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns[\"moranI\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select few genes and visualize their expression levels in the\n",
    "tissue with `scanpy.pl.spatial`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(adata, color=[\"Olfm1\", \"Plp1\", \"Itpka\", \"cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, some of these genes seems to be related to the\n",
    "*pyramidal* layers and the *fiber tract*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
